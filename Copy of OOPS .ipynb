{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_0EKPcZ0eihq98W0BoDL8O1RDMmwt6_o","timestamp":1721181028789}],"authorship_tag":"ABX9TyOp0aEpxR5DUaESpuljBpsC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3dawNv4XyX7"},"outputs":[],"source":["import numpy as np\n","\n","class ConvLayer:\n","    def __init__(self, num_filters, filter_size):\n","        self.num_filters = num_filters\n","        self.filter_size = filter_size\n","        self.filters = np.random.randn(num_filters, filter_size, filter_size) / filter_size**2\n","\n","    def iterate_regions(self, image):\n","        h, w = image.shape\n","        for i in range(h - self.filter_size + 1):\n","            for j in range(w - self.filter_size + 1):\n","                yield image[i:(i + self.filter_size), j:(j + self.filter_size)], i, j\n","\n","    def forward(self, input):\n","        self.last_input = input\n","        h, w = input.shape\n","        output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n","\n","        for region, i, j in self.iterate_regions(input):\n","            output[i, j] = np.sum(region * self.filters, axis=(1, 2))\n","        return output\n","\n","    def backprop(self, d_L_d_out, learning_rate):\n","        d_L_d_filters = np.zeros(self.filters.shape)\n","        for region, i, j in self.iterate_regions(self.last_input):\n","            for f in range(self.num_filters):\n","                d_L_d_filters[f] += d_L_d_out[i, j, f] * region\n","\n","        self.filters -= learning_rate * d_L_d_filters\n","        return None\n","\n","class MaxPoolLayer:\n","    def __init__(self, pool_size):\n","        self.pool_size = pool_size\n","\n","    def iterate_regions(self, image):\n","        h, w, _ = image.shape\n","        new_h = h // self.pool_size\n","        new_w = w // self.pool_size\n","\n","        for i in range(new_h):\n","            for j in range(new_w):\n","                yield image[(i * self.pool_size):(i * self.pool_size + self.pool_size), (j * self.pool_size):(j * self.pool_size + self.pool_size)], i, j\n","\n","    def forward(self, input):\n","        self.last_input = input\n","        h, w, num_filters = input.shape\n","        output = np.zeros((h // self.pool_size, w // self.pool_size, num_filters))\n","\n","        for region, i, j in self.iterate_regions(input):\n","            output[i, j] = np.amax(region, axis=(0, 1))\n","        return output\n","\n","    def backprop(self, d_L_d_out):\n","        d_L_d_input = np.zeros(self.last_input.shape)\n","\n","        for region, i, j in self.iterate_regions(self.last_input):\n","            h, w, f = region.shape\n","            amax = np.amax(region, axis=(0, 1))\n","\n","            for i2 in range(h):\n","                for j2 in range(w):\n","                    for f2 in range(f):\n","                        if region[i2, j2, f2] == amax[f2]:\n","                            d_L_d_input[i * self.pool_size + i2, j * self.pool_size + j2, f2] = d_L_d_out[i, j, f2]\n","        return d_L_d_input\n","\n","class SoftmaxLayer:\n","    def __init__(self, input_len, nodes):\n","        self.weights = np.random.randn(input_len, nodes) / input_len\n","        self.biases = np.zeros(nodes)\n","\n","    def forward(self, input):\n","        self.last_input_shape = input.shape\n","        input = input.flatten()\n","        self.last_input = input\n","        input_len, nodes = self.weights.shape\n","\n","        totals = np.dot(input, self.weights) + self.biases\n","        self.last_totals = totals\n","\n","        exp = np.exp(totals)\n","        return exp / np.sum(exp, axis=0)\n","\n","    def backprop(self, d_L_d_out, learning_rate):\n","        for i, gradient in enumerate(d_L_d_out):\n","            if gradient == 0:\n","                continue\n","\n","            t_exp = np.exp(self.last_totals)\n","            S = np.sum(t_exp)\n","\n","            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n","            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n","\n","            d_t_d_w = self.last_input\n","            d_t_d_b = 1\n","            d_t_d_inputs = self.weights\n","\n","            d_L_d_t = gradient * d_out_d_t\n","\n","            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n","            d_L_d_b = d_L_d_t * d_t_d_b\n","            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n","\n","            self.weights -= learning_rate * d_L_d_w\n","            self.biases -= learning_rate * d_L_d_b\n","            return d_L_d_inputs.reshape(self.last_input_shape)\n","\n","class CNN:\n","    def __init__(self):\n","        self.conv = ConvLayer(8, 3)\n","        self.pool = MaxPoolLayer(2)\n","        self.softmax = SoftmaxLayer(13 * 13 * 8, 10)\n","\n","    def forward(self, image):\n","        output = self.conv.forward(image)\n","        output = self.pool.forward(output)\n","        output = self.softmax.forward(output)\n","        return output\n","\n","    def train(self, image, label, lr=0.005):\n","        output = self.forward(image)\n","        loss = -np.log(output[label])\n","        acc = 1 if np.argmax(output) == label else 0\n","\n","        gradient = np.zeros(10)\n","        gradient[label] = -1 / output[label]\n","\n","        gradient = self.softmax.backprop(gradient, lr)\n","        gradient = self.pool.backprop(gradient)\n","        self.conv.backprop(gradient, lr)\n","\n","        return loss, acc\n","\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","class RNNLayer:\n","    def __init__(self, input_size, output_size, hidden_size):\n","        self.Whh = np.random.randn(hidden_size, hidden_size) / 1000\n","        self.Wxh = np.random.randn(hidden_size, input_size) / 1000\n","        self.Why = np.random.randn(output_size, hidden_size) / 1000\n","\n","        self.bh = np.zeros((hidden_size, 1))\n","        self.by = np.zeros((output_size, 1))\n","\n","    def forward(self, inputs):\n","        self.last_inputs = inputs\n","        self.last_hs = {0: np.zeros((self.Whh.shape[0], 1))}\n","\n","        for i, x in enumerate(inputs):\n","            self.last_hs[i + 1] = np.tanh(\n","                self.Wxh @ x + self.Whh @ self.last_hs[i] + self.bh\n","            )\n","\n","        return self.Why @ self.last_hs[len(inputs)] + self.by\n","\n","    def backprop(self, d_y, learning_rate=2e-2):\n","        n = len(self.last_inputs)\n","\n","        d_Why = d_y @ self.last_hs[n].T\n","        d_by = d_y\n","\n","        d_Whh = np.zeros(self.Whh.shape)\n","        d_Wxh = np.zeros(self.Wxh.shape)\n","        d_bh = np.zeros(self.bh.shape)\n","\n","        d_h = self.Why.T @ d_y\n","\n","        for t in reversed(range(n)):\n","            temp = ((1 - self.last_hs[t + 1] ** 2) * d_h)\n","            d_bh += temp\n","            d_Whh += temp @ self.last_hs[t].T\n","            d_Wxh += temp @ self.last_inputs[t].T\n","\n","            d_h = self.Whh @ temp\n","\n","        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n","            np.clip(d, -1, 1, out=d)\n","\n","        self.Whh -= learning_rate * d_Whh\n","        self.Wxh -= learning_rate * d_Wxh\n","        self.Why -= learning_rate * d_Why\n","        self.bh -= learning_rate * d_bh\n","        self.by -= learning_rate * d_by\n","\n","class RNN:\n","    def __init__(self, input_size, output_size, hidden_size):\n","        self.rnn_layer = RNNLayer(input_size, output_size, hidden_size)\n","\n","    def forward(self, inputs):\n","        return self.rnn_layer.forward(inputs)\n","\n","    def train(self, inputs, targets, learning_rate=2e-2):\n","        out = self.forward(inputs)\n","        loss = np.sum((out - targets) ** 2) / out.shape[0]\n","\n","        d_L_d_y = 2 * (out - targets) / out.shape[0]\n","        self.rnn_layer.backprop(d_L_d_y, learning_rate)\n","\n","        return loss\n","\n","\n","``\n"],"metadata":{"id":"ZX0kIQyyXzet"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eOwBMsEcXzhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eA9ulwleXzkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I0z_-9wRXzmO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HoR1eu6hXznV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"o2BiDusUXzpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F-vDPPDIXzss"},"execution_count":null,"outputs":[]}]}